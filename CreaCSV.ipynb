{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio del script\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CA_OwnerID                          EntityCode EntityType Services  \\\n",
      "0     BG_BNB  PSD_EMI!BG_BNB!205968825!204892794     PSD_AG      NaN   \n",
      "1     BG_BNB  PSD_EMI!BG_BNB!205968825!205762565     PSD_AG      NaN   \n",
      "2     BG_BNB  PSD_EMI!BG_BNB!205968825!203093257     PSD_AG      NaN   \n",
      "3     BG_BNB  PSD_EMI!BG_BNB!205968825!200415137     PSD_AG      NaN   \n",
      "4     BG_BNB  PSD_EMI!BG_BNB!205968825!206802144     PSD_AG      NaN   \n",
      "\n",
      "  __EBA_EntityVersion ENT_NAT_REF_COD  \\\n",
      "0   20250321140709487       204892794   \n",
      "1   20250321140833323       205762565   \n",
      "2   20250321140958052       203093257   \n",
      "3   20250321141117316       200415137   \n",
      "4   20250321141237403       206802144   \n",
      "\n",
      "                                             ENT_NAM  \\\n",
      "0                     [Пиза - Д ЕООД, Piza - D EOOD]   \n",
      "1           [Сотиров транс ЕООД, Sotirov trans EOOD]   \n",
      "2  [Естрея-Емануил Милков ЕООД, Estreya-Emanuil M...   \n",
      "3          [Шаренкапови 7 ЕООД, Sharenkapovi 7 EOOD]   \n",
      "4                         [Трантор ООД, Trantor OOD]   \n",
      "\n",
      "                                    ENT_ADD ENT_TOW_CIT_RES ENT_POS_COD  \\\n",
      "0                         4 Bozhuritsa str.          Pleven        5800   \n",
      "1    2 Trakia str., entr. B, fl. 2, app. 21       Kaspichan        9930   \n",
      "2     20 Georgi Kirkov str., fl. 4, app. 12         Dobrich        9300   \n",
      "3                          15 Sheynovo str.         Samokov        2000   \n",
      "4  29 Maritsa blvd., Severen dist., app. 15         Plovdiv        4003   \n",
      "\n",
      "  ENT_COU_RES ENT_TYP_PAR_ENT           ENT_COD_PAR_ENT DER_CHI_ENT_AUT  \n",
      "0          BG         PSD_EMI  PSD_EMI!BG_BNB!205968825        Inactive  \n",
      "1          BG         PSD_EMI  PSD_EMI!BG_BNB!205968825        Inactive  \n",
      "2          BG         PSD_EMI  PSD_EMI!BG_BNB!205968825        Inactive  \n",
      "3          BG         PSD_EMI  PSD_EMI!BG_BNB!205968825        Inactive  \n",
      "4          BG         PSD_EMI  PSD_EMI!BG_BNB!205968825          Active  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guada\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3325: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.3\n",
      "    Cod_CCAA                         CCAA  Cod_CP               Provincia  \\\n",
      "0          1                    Andalucía       4                 Almería   \n",
      "1          1                    Andalucía      11                   Cádiz   \n",
      "2          1                    Andalucía      14                 Córdoba   \n",
      "3          1                    Andalucía      18                 Granada   \n",
      "4          1                    Andalucía      21                  Huelva   \n",
      "5          1                    Andalucía      23                    Jaén   \n",
      "6          1                    Andalucía      29                  Málaga   \n",
      "7          1                    Andalucía      41                 Sevilla   \n",
      "8          2                       Aragón      22                  Huesca   \n",
      "9          2                       Aragón      44                  Teruel   \n",
      "10         2                       Aragón      50                Zaragoza   \n",
      "11         3      Asturias, Principado de      33                Asturias   \n",
      "12         4               Balears, Illes       7          Balears, Illes   \n",
      "13         5                     Canarias      35             Palmas, Las   \n",
      "14         5                     Canarias      38  Santa Cruz de Tenerife   \n",
      "15         6                    Cantabria      39               Cantabria   \n",
      "16         7              Castilla y León       5                   Ávila   \n",
      "17         7              Castilla y León       9                  Burgos   \n",
      "18         7              Castilla y León      24                    León   \n",
      "19         7              Castilla y León      34                Palencia   \n",
      "20         7              Castilla y León      37               Salamanca   \n",
      "21         7              Castilla y León      40                 Segovia   \n",
      "22         7              Castilla y León      42                   Soria   \n",
      "23         7              Castilla y León      47              Valladolid   \n",
      "24         7              Castilla y León      49                  Zamora   \n",
      "25         8           Castilla-La Mancha       2                Albacete   \n",
      "26         8           Castilla-La Mancha      13             Ciudad Real   \n",
      "27         8           Castilla-La Mancha      16                  Cuenca   \n",
      "28         8           Castilla-La Mancha      19             Guadalajara   \n",
      "29         8           Castilla-La Mancha      45                  Toledo   \n",
      "30         9                     Cataluña       8               Barcelona   \n",
      "31         9                     Cataluña      17                  Girona   \n",
      "32         9                     Cataluña      25                  Lleida   \n",
      "33         9                     Cataluña      43               Tarragona   \n",
      "34        10         Comunitat Valenciana       3        Alicante/Alacant   \n",
      "35        10         Comunitat Valenciana      12      Castellón/Castelló   \n",
      "36        10         Comunitat Valenciana      46       Valencia/València   \n",
      "37        11                  Extremadura       6                 Badajoz   \n",
      "38        11                  Extremadura      10                 Cáceres   \n",
      "39        12                      Galicia      15               Coruña, A   \n",
      "40        12                      Galicia      27                    Lugo   \n",
      "41        12                      Galicia      32                 Ourense   \n",
      "42        12                      Galicia      36              Pontevedra   \n",
      "43        13         Madrid, Comunidad de      28                  Madrid   \n",
      "44        14            Murcia, Región de      30                  Murcia   \n",
      "45        15  Navarra, Comunidad Foral de      31                 Navarra   \n",
      "46        16                   País Vasco       1             Araba/Álava   \n",
      "47        16                   País Vasco      48                 Bizkaia   \n",
      "48        16                   País Vasco      20                Gipuzkoa   \n",
      "49        18                        Ceuta      51                   Ceuta   \n",
      "50        19                      Melilla      52                 Melilla   \n",
      "\n",
      "                          CCAA2  \n",
      "0                     Andalucía  \n",
      "1                     Andalucía  \n",
      "2                     Andalucía  \n",
      "3                     Andalucía  \n",
      "4                     Andalucía  \n",
      "5                     Andalucía  \n",
      "6                     Andalucía  \n",
      "7                     Andalucía  \n",
      "8                        Aragón  \n",
      "9                        Aragón  \n",
      "10                       Aragón  \n",
      "11      Asturias, Principado de  \n",
      "12               Balears, Illes  \n",
      "13                     Canarias  \n",
      "14                     Canarias  \n",
      "15                    Cantabria  \n",
      "16              Castilla y León  \n",
      "17              Castilla y León  \n",
      "18              Castilla y León  \n",
      "19              Castilla y León  \n",
      "20              Castilla y León  \n",
      "21              Castilla y León  \n",
      "22              Castilla y León  \n",
      "23              Castilla y León  \n",
      "24              Castilla y León  \n",
      "25           Castilla-La Mancha  \n",
      "26           Castilla-La Mancha  \n",
      "27           Castilla-La Mancha  \n",
      "28           Castilla-La Mancha  \n",
      "29           Castilla-La Mancha  \n",
      "30                     Cataluña  \n",
      "31                     Cataluña  \n",
      "32                     Cataluña  \n",
      "33                     Cataluña  \n",
      "34         Comunitat Valenciana  \n",
      "35         Comunitat Valenciana  \n",
      "36         Comunitat Valenciana  \n",
      "37                  Extremadura  \n",
      "38                  Extremadura  \n",
      "39                      Galicia  \n",
      "40                      Galicia  \n",
      "41                      Galicia  \n",
      "42                      Galicia  \n",
      "43         Madrid, Comunidad de  \n",
      "44            Murcia, Región de  \n",
      "45  Navarra, Comunidad Foral de  \n",
      "46                   País Vasco  \n",
      "47                   País Vasco  \n",
      "48                   País Vasco  \n",
      "49                        Ceuta  \n",
      "50                      Melilla  \n",
      "       Municipio Provincia                        CCAA2 Código postal\n",
      "0             nd       NaN                          NaN         000nd\n",
      "1         Ababuj    Teruel                       Aragón         44001\n",
      "2         Abades   Segovia              Castilla y León         40001\n",
      "3         Abadía   Cáceres                  Extremadura         10001\n",
      "4         Abadín      Lugo                      Galicia         27001\n",
      "...          ...       ...                          ...           ...\n",
      "8131      Zumaia  Gipuzkoa                   País Vasco         20081\n",
      "8132   Zumarraga  Gipuzkoa                   País Vasco         20080\n",
      "8133      Zuñeda    Burgos              Castilla y León         09485\n",
      "8134      Zúñiga   Navarra  Navarra, Comunidad Foral de         31265\n",
      "8135     Zurgena   Almería                    Andalucía         04103\n",
      "\n",
      "[8136 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guada\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:222: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\guada\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:225: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script de procesado de agentes EBA.\n",
    "===================================\n",
    "Este script carga un archivo JSON con información de agentes de pago (PSD_AG),\n",
    "expande la columna \"Properties\", filtra por determinados criterios,\n",
    "normaliza algunas columnas y cruza los datos con listados de municipios\n",
    "españoles y códigos de comunidades autónomas.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Importación de librerías\n",
    "# -----------------------------\n",
    "import tkinter as tk                 # GUI minimal para diálogos de selección de archivos\n",
    "from tkinter import filedialog       # Diálogo de archivos de Tkinter\n",
    "import json                          # Manejo de archivos JSON\n",
    "import pandas as pd                  # Manipulación de datos en DataFrames\n",
    "import re                            # Expresiones regulares\n",
    "import openpyxl                      # Lectura/escritura de archivos Excel\n",
    "from fuzzywuzzy import fuzz          # Coincidencia difusa (no se usa en la lógica actual)\n",
    "from fuzzywuzzy import process       # Utilidades adicionales de fuzzywuzzy\n",
    "from faker import Faker              # Generador de datos falsos (no se usa en la lógica actual)\n",
    "import random                        # Generador de números aleatorios (no se usa en la lógica actual)\n",
    "from datetime import datetime, time  # Manejo de fechas y horas\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Inicio del procesamiento\n",
    "# -----------------------------\n",
    "print(\"Inicio del script\")\n",
    "\n",
    "# Configuramos una ventana raíz oculta de Tkinter para utilizar sus diálogos\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Oculta la ventana principal para que solo se vea el diálogo\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. Selección y carga del archivo JSON EBA\n",
    "# -----------------------------------------\n",
    "\n",
    "ruta_archivo = filedialog.askopenfilename()  # Diálogo para seleccionar el JSON de agentes EBA\n",
    "\n",
    "if ruta_archivo:\n",
    "    try:\n",
    "        with open(ruta_archivo, encoding=\"utf8\") as file:\n",
    "            data = json.load(file)  # Carga el JSON como estructura Python\n",
    "            print(data)            # Muestra el contenido (útil para depuración)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo '{ruta_archivo}' no fue encontrado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error: {e}\")\n",
    "else:\n",
    "    print(\"No se seleccionó ningún archivo.\")\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4. Conversión del JSON a DataFrame y filtrado de agentes\n",
    "# --------------------------------------------------------\n",
    "\n",
    "pagos = pd.DataFrame(data[1])  # Se asume que la lista en data[1] contiene los registros\n",
    "\n",
    "# Filtrar solo entidades de tipo PSD_AG (agentes)\n",
    "agentes = pagos[pagos['EntityType'] == 'PSD_AG']\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 5. Función para expandir el campo \"Properties\" en columnas individuales\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "def expand_properties(df):\n",
    "    \"\"\"Expande la columna 'Properties' en columnas separadas.\n",
    "\n",
    "    Cada elemento de 'Properties' es una lista de diccionarios. La función\n",
    "    crea un DataFrame auxiliar con la unión de todos esos diccionarios y lo\n",
    "    concatena al DataFrame original (sin la columna 'Properties').\n",
    "    \"\"\"\n",
    "    properties_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        prop_dict = {}\n",
    "        if isinstance(row['Properties'], list):\n",
    "            for prop in row['Properties']:\n",
    "                if isinstance(prop, dict):\n",
    "                    prop_dict.update(prop)  # Une los pares clave‑valor\n",
    "        properties_data.append(prop_dict)\n",
    "\n",
    "    properties_df = pd.DataFrame(properties_data)\n",
    "\n",
    "    # Sustituye la columna original por las nuevas columnas expandidas\n",
    "    df = pd.concat([\n",
    "        df.drop('Properties', axis=1).reset_index(drop=True),\n",
    "        properties_df.reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    return df\n",
    "\n",
    "# Aplicamos la expansión si existe al menos un registro\n",
    "if not agentes.empty:\n",
    "    agentes_expandido = expand_properties(agentes)\n",
    "    print(agentes_expandido.head())  # Vista rápida del resultado\n",
    "else:\n",
    "    print(\"El DataFrame está vacío, no se pueden expandir las propiedades.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6. Filtrado por columnas específicas en bloques (chunks) grandes\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "chunk_size = 10000  # Procesamos en trozos para limitar uso de memoria\n",
    "filtered_chunks = []  # Almacenamos los trozos que cumplen la condición\n",
    "\n",
    "for i in range(0, len(agentes_expandido), chunk_size):\n",
    "    chunk = agentes_expandido.iloc[i:i + chunk_size]\n",
    "    # Condiciones de filtrado\n",
    "    filtered_chunk = chunk[\n",
    "        (chunk['ENT_COU_RES'] == 'ES') &      # País de residencia = España\n",
    "        (chunk['ENT_TYP_PAR_ENT'] == 'PSD_PI') &  # Tipo de entidad parental = PSD_PI\n",
    "        (chunk['DER_CHI_ENT_AUT'] == 'Active')    # Estado de autorización = Activo\n",
    "    ]\n",
    "    filtered_chunks.append(filtered_chunk)\n",
    "\n",
    "# Unión de todos los trozos filtrados\n",
    "agentes_filtrado = pd.concat(filtered_chunks)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 7. Eliminación de columnas irrelevantes o repetidas\n",
    "# --------------------------------------------------\n",
    "\n",
    "columnas_a_eliminar = [\n",
    "    \"CA_OwnerID\",\n",
    "    \"EntityCode\",\n",
    "    \"EntityType\",\n",
    "    \"Services\",\n",
    "    \"__EBA_EntityVersion\",\n",
    "    \"DER_CHI_ENT_AUT\",\n",
    "    \"ENT_COU_RES\",\n",
    "    \"ENT_TYP_PAR_ENT\"\n",
    "]\n",
    "\n",
    "agentes_filtrado = agentes_filtrado.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 8. Normalización de valores de ciudad y código postal en el DataFrame\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "def separar_letras_numeros(df):\n",
    "    \"\"\"Separa letras y números en 'ENT_TOW_CIT_RES' y rellena 'ENT_POS_COD'.\"\"\"\n",
    "    for i, row in df.iterrows():\n",
    "        text = ''.join(re.findall(r'[^\\d]+', str(row['ENT_TOW_CIT_RES'])))  # Solo letras\n",
    "        numbers = ''.join(re.findall(r'\\d+', str(row['ENT_TOW_CIT_RES'])))  # Solo números\n",
    "        df.at[i, 'ENT_TOW_CIT_RES'] = text  # Reemplaza con solo letras\n",
    "        # Solo se actualiza ENT_POS_COD si está vacío o no es numérico\n",
    "        if numbers and not str(row['ENT_POS_COD']).isdigit():\n",
    "            df.at[i, 'ENT_POS_COD'] = numbers\n",
    "        elif not str(row['ENT_POS_COD']).isdigit():\n",
    "            df.at[i, 'ENT_POS_COD'] = ''\n",
    "    return df\n",
    "\n",
    "agentes_c = separar_letras_numeros(agentes_filtrado)\n",
    "\n",
    "# Pone la columna de ciudades en formato Title Case\n",
    "def title_case(s):\n",
    "    return ' '.join(word.capitalize() for word in s.split())\n",
    "\n",
    "agentes_c['ENT_TOW_CIT_RES'] = agentes_c['ENT_TOW_CIT_RES'].apply(title_case)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9. Carga de listado de municipios españoles desde CSV\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Oculta la ventana de Tkinter para otro diálogo\n",
    "\n",
    "ruta_archivo = filedialog.askopenfilename()  # Selección del CSV de municipios\n",
    "\n",
    "municipios_df = None  # Inicializamos\n",
    "\n",
    "if ruta_archivo:\n",
    "    try:\n",
    "        municipios_df = pd.read_csv(ruta_archivo, encoding='utf-8-sig', sep=';')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo '{ruta_archivo}' no fue encontrado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error: {e}\")\n",
    "else:\n",
    "    print(\"No se seleccionó ningún archivo.\")\n",
    "\n",
    "# Limpieza de índice (por si el CSV ya viene con uno)\n",
    "municipios_dfs = municipios_df.reset_index(drop=True)\n",
    "municipios_df1 = municipios_dfs.dropna(how='all')  # Elimina filas completamente vacías\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10. Carga del CSV con correspondencia de CCAA ↔ Código postal\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(openpyxl.__version__)  # Muestra versión de openpyxl (debug)\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "ruta_archivo = filedialog.askopenfilename()  # Selección del CSV de CCAA\n",
    "\n",
    "CCAA_df = None\n",
    "\n",
    "if ruta_archivo:\n",
    "    try:\n",
    "        CCAA_df = pd.read_csv(ruta_archivo, encoding='utf-8-sig', sep=';')\n",
    "        CCAA_df1 = CCAA_df.reset_index(drop=True).dropna(how='all')\n",
    "\n",
    "        if not CCAA_df1.empty:\n",
    "            print(CCAA_df1)  # Vista previa\n",
    "        else:\n",
    "            print(\"El archivo CSV está vacío o no contiene datos válidos.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: El archivo '{ruta_archivo}' no fue encontrado.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error: No se pudo analizar el archivo CSV. Verifica el formato.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado: {e}\")\n",
    "else:\n",
    "    print(\"No se seleccionó ningún archivo.\")\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 11. Cruce entre municipios y códigos de CCAA a partir del código postal\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# 1) Asegura que los CP tengan 5 dígitos con ceros a la izquierda\n",
    "municipios_df1['Código postal'] = municipios_df1['Código postal'].astype(str).str.zfill(5)\n",
    "\n",
    "# 2) Extrae los dos primeros dígitos del CP para enlazar con la tabla de CCAA\n",
    "municipios_df1['Cod_cp_temp'] = municipios_df1['Código postal'].str[:2]\n",
    "\n",
    "# 3) Convierte a string y rellena con ceros la columna de códigos en CCAA\n",
    "CCAA_df1['Cod_CP'] = CCAA_df1['Cod_CP'].astype(str).str.zfill(2)\n",
    "\n",
    "# 4) Realiza el merge entre ambos DataFrames\n",
    "municipios_df1 = pd.merge(\n",
    "    municipios_df1,\n",
    "    CCAA_df1,\n",
    "    left_on='Cod_cp_temp',\n",
    "    right_on='Cod_CP',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 5) Reordena las columnas para un resultado más claro\n",
    "municipios_df1 = municipios_df1[['Municipio', 'Provincia', 'CCAA2', 'Código postal', 'Cod_cp_temp', 'Cod_CP']]\n",
    "\n",
    "# 6) Elimina columnas temporales utilizadas durante el merge\n",
    "municipios_df2 = municipios_df1.drop(['Cod_cp_temp', 'Cod_CP'], axis=1)\n",
    "\n",
    "# Muestra el DataFrame final resultante\n",
    "print(municipios_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\guada\\anaconda3\\lib\\site-packages (3.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\guada\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\guada\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ENT_NAT_REF_COD                                ENT_NAM  \\\n",
      "0                       Y4785493N                          NIGAR SULTANA   \n",
      "1                       02395680T          NAOUAL EL KOURACHI EL BACHIRI   \n",
      "2                       B86261252                          RICTELECOM SL   \n",
      "3                       B67299792                        BHALOT BROS S L   \n",
      "4                       Y6487752H                   JAKAIRA HOSSAIN KHAN   \n",
      "...                           ...                                    ...   \n",
      "25634                   Y1641002N    JUAN MATOS REYES - AGENTE IN SPAGNA   \n",
      "25635                   Y2701905V     MEHTAB IFTIKHAR - AGENTE IN SPAGNA   \n",
      "25636                   Y2838493P    MD KAMRUL  HASAN - AGENTE IN SPAGNA   \n",
      "25637                   Y3333433B  MONIRUZZAMAN MONIR - AGENTE IN SPAGNA   \n",
      "25638  PSD_PI!FR_ACPR!49786!51599                          WPS ESPANA SA   \n",
      "\n",
      "                                                 ENT_ADD  \\\n",
      "0                                 PLAZA LAVAPIES 8 BJ LC   \n",
      "1                            CRER JOAN FIVELLER 32 PBJ 1   \n",
      "2                                     C MOVINDA 12 LOCAL   \n",
      "3                                     CL TIBIDABO NUM 70   \n",
      "4                          AVDA FRANCIA 68 PBJ 5 LA MATA   \n",
      "...                                                  ...   \n",
      "25634                                     CALLE LA PAZ 3   \n",
      "25635                                    CALLE ZURITA 47   \n",
      "25636                                    CALLE OLIVAR 47   \n",
      "25637                                  CALLE TRIBULETE 5   \n",
      "25638  [Vallespir 19 Edificio Octavia, Modulo3 Planta...   \n",
      "\n",
      "                ENT_TOW_CIT_RES ENT_POS_COD           ENT_COD_PAR_ENT  \\\n",
      "0                        Madrid       28012         BE_NBB!0671690653   \n",
      "1                    Viladecans       08840         BE_NBB!0671690653   \n",
      "2                        Madrid       28037         BE_NBB!0671690653   \n",
      "3            Barbera Del Valles       08210         BE_NBB!0671690653   \n",
      "4                    Torrevieja       03188         BE_NBB!0671690653   \n",
      "...                         ...         ...                       ...   \n",
      "25634  Santa Coloma De Gramenet        8923  PSD_PI!IT_BI!09145191004   \n",
      "25635                    Madrid       28012  PSD_PI!IT_BI!09145191004   \n",
      "25636                    Madrid       28012  PSD_PI!IT_BI!09145191004   \n",
      "25637                    Madrid       28012  PSD_PI!IT_BI!09145191004   \n",
      "25638     Sant Cugat Del Valles       08173             FR_ACPR!49786   \n",
      "\n",
      "              Provincia                 CCAA2 Código postal  \n",
      "0                Madrid  Madrid, Comunidad de         28079  \n",
      "1             Barcelona              Cataluña         08301  \n",
      "2                Madrid  Madrid, Comunidad de         28079  \n",
      "3                   NaN                   NaN           NaN  \n",
      "4      Alicante/Alacant  Comunitat Valenciana         03133  \n",
      "...                 ...                   ...           ...  \n",
      "25634         Barcelona              Cataluña         08245  \n",
      "25635            Madrid  Madrid, Comunidad de         28079  \n",
      "25636            Madrid  Madrid, Comunidad de         28079  \n",
      "25637            Madrid  Madrid, Comunidad de         28079  \n",
      "25638         Barcelona              Cataluña         08205  \n",
      "\n",
      "[25639 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fuzzy‑matching de nombres de municipio con RapidFuzz\n",
    "===================================\n",
    "Este script devuelve los datos de municipios entre dos ficheros.\n",
    "\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "# Imports necesarios (pandas ya estaba usado en el bloque principal)\n",
    "!pip install rapidfuzz\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process  # rapidfuzz ofrece matching difuso rápido\n",
    "\n",
    "\n",
    "def encontrar_mejores_coincidencias_rapidfuzz_con_cache(\n",
    "    municipios_data6: pd.Series | list[str],\n",
    "    lista_municipios: list[str],\n",
    "    umbral: int = 85,\n",
    "):\n",
    "    \"\"\"Devuelve la mejor coincidencia difusa para cada municipio.\n",
    "\n",
    "    * **municipios_data6**: iterable con los nombres a buscar.\n",
    "    * **lista_municipios**: universo de comparación (nombres oficiales).\n",
    "    * **umbral**: porcentaje mínimo (0‑100) de similitud aceptado.\n",
    "    * Usa un **cache** interno para no recalcular coincidencias repetidas.\n",
    "    \"\"\"\n",
    "    cache: dict[str, str | None] = {}\n",
    "    resultados: list[str | None] = []\n",
    "\n",
    "    for municipio in municipios_data6:\n",
    "        # Si ya calculamos este municipio, recuperamos el resultado del cache\n",
    "        if municipio in cache:\n",
    "            resultados.append(cache[municipio])\n",
    "            continue\n",
    "\n",
    "        # Buscamos la coincidencia más parecida en lista_municipios\n",
    "        mejor_coincidencia, similitud, _ = process.extractOne(\n",
    "            municipio,\n",
    "            lista_municipios,\n",
    "            scorer=fuzz.ratio,  # Métrica de similitud (0‑100)\n",
    "        )\n",
    "\n",
    "        # Solo aceptamos la coincidencia si supera el umbral indicado\n",
    "        if similitud >= umbral:\n",
    "            cache[municipio] = mejor_coincidencia\n",
    "        else:\n",
    "            cache[municipio] = None  # Marcamos como sin coincidencia válida\n",
    "        resultados.append(cache[municipio])\n",
    "\n",
    "    return resultados\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Ejecución del matching y merge con el DataFrame de municipios\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Convertimos la columna \"Municipio\" a lista una única vez para evitar\n",
    "# recalcularla en cada iteración de RapidFuzz.\n",
    "lista_municipios = municipios_df2[\"Municipio\"].tolist()\n",
    "\n",
    "# Añadimos la columna con la mejor coincidencia encontrada\n",
    "agentes_c[\"Mejor_Coincidencia\"] = encontrar_mejores_coincidencias_rapidfuzz_con_cache(\n",
    "    agentes_c[\"ENT_TOW_CIT_RES\"],\n",
    "    lista_municipios,\n",
    ")\n",
    "\n",
    "# Hacemos un *merge* usando la coincidencia encontrada ↔ municipio oficial\n",
    "agentes_c_con_municipios = pd.merge(\n",
    "    agentes_c,\n",
    "    municipios_df2,\n",
    "    left_on=\"Mejor_Coincidencia\",\n",
    "    right_on=\"Municipio\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Eliminamos columnas auxiliares para dejar el DataFrame final limpio\n",
    "agentes_c_con_municipios = agentes_c_con_municipios.drop(\n",
    "    [\"Mejor_Coincidencia\", \"Municipio\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Mostramos el resultado (o podrías guardarlo a disco)\n",
    "print(agentes_c_con_municipios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduce el número de ficheros CSV a generar: 50\n",
      "Fichero Sujeto_Obligado8__Agente540.csv generado con 1045 transacciones.\n",
      "Fichero Sujeto_Obligado5__Agente7779.csv generado con 611 transacciones.\n",
      "Fichero Sujeto_Obligado13__Agente14026.csv generado con 856 transacciones.\n",
      "Fichero Sujeto_Obligado10__Agente437.csv generado con 705 transacciones.\n",
      "Fichero Sujeto_Obligado10__Agente2427.csv generado con 429 transacciones.\n",
      "Fichero Sujeto_Obligado3__Agente6623.csv generado con 593 transacciones.\n",
      "Fichero Sujeto_Obligado8__Agente6393.csv generado con 717 transacciones.\n",
      "Fichero Sujeto_Obligado8__Agente3285.csv generado con 820 transacciones.\n",
      "Fichero Sujeto_Obligado12__Agente1108.csv generado con 773 transacciones.\n",
      "Fichero Sujeto_Obligado12__Agente2264.csv generado con 931 transacciones.\n",
      "Fichero Sujeto_Obligado3__Agente9519.csv generado con 698 transacciones.\n",
      "Fichero Sujeto_Obligado8__Agente7391.csv generado con 1160 transacciones.\n",
      "Fichero Sujeto_Obligado6__Agente959.csv generado con 833 transacciones.\n",
      "Fichero Sujeto_Obligado6__Agente2566.csv generado con 781 transacciones.\n",
      "Fichero Sujeto_Obligado2__Agente6055.csv generado con 1121 transacciones.\n",
      "Fichero Sujeto_Obligado12__Agente1595.csv generado con 492 transacciones.\n",
      "Fichero Sujeto_Obligado12__Agente1114.csv generado con 759 transacciones.\n",
      "Fichero Sujeto_Obligado10__Agente6866.csv generado con 1131 transacciones.\n",
      "Fichero Sujeto_Obligado13__Agente1168.csv generado con 1151 transacciones.\n",
      "Fichero Sujeto_Obligado2__Agente7208.csv generado con 424 transacciones.\n",
      "Fichero Sujeto_Obligado13__Agente13550.csv generado con 1145 transacciones.\n",
      "Fichero Sujeto_Obligado1__Agente12083.csv generado con 943 transacciones.\n",
      "Fichero Sujeto_Obligado12__Agente8055.csv generado con 948 transacciones.\n",
      "Fichero Sujeto_Obligado12__Agente4614.csv generado con 435 transacciones.\n",
      "Fichero Sujeto_Obligado4__Agente7333.csv generado con 941 transacciones.\n",
      "Fichero Sujeto_Obligado1__Agente4744.csv generado con 487 transacciones.\n",
      "Fichero Sujeto_Obligado12__Agente7154.csv generado con 559 transacciones.\n",
      "Fichero Sujeto_Obligado3__Agente4585.csv generado con 604 transacciones.\n",
      "Fichero Sujeto_Obligado4__Agente3064.csv generado con 572 transacciones.\n",
      "Fichero Sujeto_Obligado12__Agente10196.csv generado con 889 transacciones.\n",
      "Fichero Sujeto_Obligado3__Agente5688.csv generado con 827 transacciones.\n",
      "Fichero Sujeto_Obligado9__Agente12657.csv generado con 454 transacciones.\n",
      "Fichero Sujeto_Obligado11__Agente8224.csv generado con 684 transacciones.\n",
      "Fichero Sujeto_Obligado5__Agente6888.csv generado con 967 transacciones.\n",
      "Fichero Sujeto_Obligado11__Agente8905.csv generado con 312 transacciones.\n",
      "Fichero Sujeto_Obligado11__Agente7824.csv generado con 523 transacciones.\n",
      "Fichero Sujeto_Obligado4__Agente7346.csv generado con 1128 transacciones.\n",
      "Fichero Sujeto_Obligado9__Agente11177.csv generado con 656 transacciones.\n",
      "Fichero Sujeto_Obligado13__Agente13807.csv generado con 554 transacciones.\n",
      "Fichero Sujeto_Obligado4__Agente10596.csv generado con 543 transacciones.\n",
      "Fichero Sujeto_Obligado3__Agente1432.csv generado con 690 transacciones.\n",
      "Fichero Sujeto_Obligado8__Agente2658.csv generado con 343 transacciones.\n",
      "Fichero Sujeto_Obligado3__Agente10006.csv generado con 485 transacciones.\n",
      "Fichero Sujeto_Obligado3__Agente6771.csv generado con 621 transacciones.\n",
      "Fichero Sujeto_Obligado8__Agente11234.csv generado con 550 transacciones.\n",
      "Fichero Sujeto_Obligado12__Agente6505.csv generado con 450 transacciones.\n",
      "Fichero Sujeto_Obligado10__Agente11594.csv generado con 989 transacciones.\n",
      "Fichero Sujeto_Obligado13__Agente4744.csv generado con 646 transacciones.\n",
      "Fichero Sujeto_Obligado3__Agente4558.csv generado con 475 transacciones.\n",
      "Fichero Sujeto_Obligado5__Agente8196.csv generado con 1087 transacciones.\n",
      "Todos los ficheros CSV han sido generados.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generador de ficheros CSV con transacciones simuladas\n",
    "===================================\n",
    "Este script genera ficheros que simulan transacciones de riesgo y\n",
    "no riesgo realizados en agentes y sus correspondientes sujetos obligados.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from faker import Faker        # Generador de datos falsos realistas\n",
    "import random                  # Utilidades de aleatoriedad de la librería estándar\n",
    "from datetime import datetime, time  # Manejo de fechas y horas\n",
    "import pandas as pd            # Manipulación tabular\n",
    "import re                      # Expresiones regulares (no se usan luego, pero lo dejamos)\n",
    "import numpy as np             # Operaciones numéricas y aleatorias vectorizadas\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Configuración inicial de Faker y nombres de archivos\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "faker = Faker('es_ES')  # Locale español para nombres y NIE\n",
    "\n",
    "# --- Solicitamos al usuario cuántos CSV debe generar ---\n",
    "num_ficheros = int(input(\"Introduce el número de ficheros CSV a generar: \"))\n",
    "# Nombres como Agente_A_Entidad_1.csv, Agente_B_Entidad_2.csv…\n",
    "ficheros = [f\"Agente_{chr(65+i)}_Entidad_{i+1}.csv\" for i in range(num_ficheros)]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. Generación de clientes ordenantes únicos\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "num_clientes_ordenantes = int(300 * 0.8)  # 80 % de 300 → 240 clientes\n",
    "clientes_ordenantes = []\n",
    "for _ in range(num_clientes_ordenantes):\n",
    "    pais = faker.country()\n",
    "    cliente = {\n",
    "        \"NOMBRE_ORDENANTE\": faker.first_name(),\n",
    "        \"APELLIDO_ORDENANTE\": faker.last_name(),\n",
    "        \"SEGUNDO_APELLIDO_ORDENANTE\": faker.last_name() if random.random() > 0.2 else '',\n",
    "        \"PAIS_DOC_ORDENANTE\": pais,\n",
    "        \"NUM_DOC_ORDENANTE\": faker.nie(),  # Número de documento (NIE)\n",
    "        \"PAIS_NAC_ORDENANTE\": faker.country(),\n",
    "        \"FECHA_NAC_ORDENANTE\": faker.date_of_birth().strftime('%d/%m/%Y'),\n",
    "        \"es_Agente\": False  # Flag que después se usará para marcar al agente designado\n",
    "    }\n",
    "    clientes_ordenantes.append(cliente)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. Beneficiarios basados en los ordenantes\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "num_beneficiarios_basados = int(300 * 0.5)  # 50 % de 300 → 150 beneficiarios\n",
    "beneficiarios_basados = []\n",
    "for ordenante in clientes_ordenantes:\n",
    "    apellido_base = ordenante['APELLIDO_ORDENANTE']\n",
    "    if random.random() < 0.9:  # 90 % comparten apellido / país con ordenante\n",
    "        beneficiario = {\n",
    "            \"NOMBRE_BENEFICIARIO\": faker.first_name(),\n",
    "            \"APELLIDO_BENEFICIARIO\": apellido_base,\n",
    "            \"SEGUNDO_APELLIDO_BENEFICIARIO\": faker.last_name() if random.random() > 0.2 else '',\n",
    "            \"PAIS_DESTINO\": ordenante['PAIS_DOC_ORDENANTE']\n",
    "        }\n",
    "    else:  # 10 % no relacionados\n",
    "        beneficiario = {\n",
    "            \"NOMBRE_BENEFICIARIO\": faker.first_name(),\n",
    "            \"APELLIDO_BENEFICIARIO\": faker.last_name(),\n",
    "            \"SEGUNDO_APELLIDO_BENEFICIARIO\": faker.last_name() if random.random() > 0.2 else '',\n",
    "            \"PAIS_DESTINO\": faker.country()\n",
    "        }\n",
    "    beneficiarios_basados.append(beneficiario)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4. Beneficiarios completamente aleatorios (20 %)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "num_beneficiarios_aleatorios = int(300 * 0.2)  # 20 % de 300 → 60 beneficiarios\n",
    "beneficiarios_aleatorios = []\n",
    "for _ in range(num_beneficiarios_aleatorios):\n",
    "    beneficiario = {\n",
    "        \"NOMBRE_BENEFICIARIO\": faker.first_name(),\n",
    "        \"APELLIDO_BENEFICIARIO\": faker.last_name(),\n",
    "        \"SEGUNDO_APELLIDO_BENEFICIARIO\": faker.last_name() if random.random() > 0.2 else '',\n",
    "        \"PAIS_DESTINO\": faker.country()\n",
    "    }\n",
    "    beneficiarios_aleatorios.append(beneficiario)\n",
    "\n",
    "# --- Unimos ambos listados ---\n",
    "beneficiarios = beneficiarios_basados + beneficiarios_aleatorios\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5. Codificación de columnas en `agentes_c_con_municipios`\n",
    "# ---------------------------------------------------------------------------\n",
    "# Este bloque reasigna códigos reales a etiquetas anónimas (\"Sujeto_ObligadoX\",\n",
    "# \"AgenteY\") para facilitar la generación de nombres de fichero.\n",
    "\n",
    "if 'ENT_COD_PAR_ENT' in agentes_c_con_municipios.columns:\n",
    "    unique_sujetos = agentes_c_con_municipios['ENT_COD_PAR_ENT'].unique()\n",
    "    sujeto_mapping = {s: f'Sujeto_Obligado{i+1}' for i, s in enumerate(unique_sujetos)}\n",
    "    agentes_c_con_municipios['ENT_COD_PAR_ENT'] = agentes_c_con_municipios['ENT_COD_PAR_ENT'].map(sujeto_mapping)\n",
    "\n",
    "if 'ENT_NAT_REF_COD' in agentes_c_con_municipios.columns:\n",
    "    unique_agentes = agentes_c_con_municipios['ENT_NAT_REF_COD'].unique()\n",
    "    agente_mapping = {a: f'Agente{i+1}' for i, a in enumerate(unique_agentes)}\n",
    "    agentes_c_con_municipios['ENT_NAT_REF_COD'] = agentes_c_con_municipios['ENT_NAT_REF_COD'].map(agente_mapping)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6. Distribución de localidades y selección de combinaciones\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "distribucion_localidades = (\n",
    "    agentes_c_con_municipios\n",
    "    .groupby(['ENT_TOW_CIT_RES', 'ENT_COD_PAR_ENT', 'ENT_NAT_REF_COD'])\n",
    "    .size()\n",
    "    .reset_index(name='counts')\n",
    ")\n",
    "total_localidades = distribucion_localidades['counts'].sum()\n",
    "distribucion_localidades['proporcion'] = distribucion_localidades['counts'] / total_localidades\n",
    "\n",
    "# Seleccionamos una combinación (ciudad + sujeto + agente) para cada fichero\n",
    "combinaciones_seleccionadas = random.choices(\n",
    "    distribucion_localidades.index,\n",
    "    weights=distribucion_localidades['proporcion'],\n",
    "    k=num_ficheros\n",
    ")\n",
    "\n",
    "# Mapeo agente → cliente designado (quien actuará como \"agente\" en los CSV)\n",
    "designated_agents = {ag: random.choice(clientes_ordenantes) for ag in agente_mapping.values()}\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 7. Bucle de generación de cada fichero CSV\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "for i, fichero in enumerate(ficheros):\n",
    "    # --------- Parámetros principales de este archivo ---------\n",
    "    num_transacciones = random.randint(300, 1200)\n",
    "    min_importe, max_importe = 50, 3000  # rango de importes en euros\n",
    "\n",
    "    # ----------------- Fechas y horas -----------------\n",
    "    fechas_aleatorias = []\n",
    "    horas_aleatorias = []\n",
    "    for _ in range(num_transacciones):\n",
    "        fecha = datetime(2023, random.randint(1, 12), random.randint(1, 28))\n",
    "        fechas_aleatorias.append(fecha.strftime('%d/%m/%Y'))\n",
    "        # 90 % en horario de oficina, 10 % aleatorio\n",
    "        if random.random() < 0.9:\n",
    "            hora_str = f\"{random.randint(9, 21):02d}:{random.randint(0, 59):02d}\"\n",
    "        else:\n",
    "            hora_str_full = faker.time()\n",
    "            try:\n",
    "                hora_str = datetime.strptime(hora_str_full, \"%H:%M:%S\").strftime(\"%H:%M\")\n",
    "            except ValueError as e:\n",
    "                print(f\"Error parsing time string: {e}\")\n",
    "                hora_str = \"00:00\"\n",
    "        horas_aleatorias.append(hora_str)\n",
    "\n",
    "    fechas_aleatorias.sort()  # opcional: ordenamos las fechas\n",
    "    importes_aleatorios = [random.randint(min_importe, max_importe) for _ in range(num_transacciones)]\n",
    "\n",
    "    def generar_numero_transaccion():\n",
    "        \"\"\"Crea un identificador único con prefijo TXN-\"\"\"\n",
    "        return 'TXN-' + ''.join(random.choices('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789', k=8))\n",
    "\n",
    "    # ---------------- Estado de operación ----------------\n",
    "    estados_operacion = random.choices(\n",
    "        ['EXITOSA', 'FALLIDA', 'CANCELADA'],\n",
    "        weights=[0.9, 0.04, 0.06],\n",
    "        k=num_transacciones\n",
    "    )\n",
    "\n",
    "    # ---------------- Ordenantes y beneficiarios ----------------\n",
    "    ordenantes_seleccionados = random.choices(clientes_ordenantes, k=num_transacciones)\n",
    "\n",
    "    # --- Forzamos que la primera transacción pertenezca al agente designado -----\n",
    "    index_seleccionado = combinaciones_seleccionadas[i]\n",
    "    agente_del_fichero = distribucion_localidades.loc[index_seleccionado, 'ENT_NAT_REF_COD']\n",
    "    cliente_agente = designated_agents[agente_del_fichero]\n",
    "    doc_agente_designado = cliente_agente[\"NUM_DOC_ORDENANTE\"]\n",
    "    if not any(o[\"NUM_DOC_ORDENANTE\"] == doc_agente_designado for o in ordenantes_seleccionados):\n",
    "        ordenantes_seleccionados[0] = cliente_agente\n",
    "\n",
    "    # ----- Selección de beneficiarios alineados con los ordenantes -----\n",
    "    beneficiarios_seleccionados = []\n",
    "    for ordenante in ordenantes_seleccionados:\n",
    "        beneficiarios_posibles = [\n",
    "            b for b in beneficiarios\n",
    "            if b['PAIS_DESTINO'] == ordenante['PAIS_DOC_ORDENANTE'] and (\n",
    "                b['APELLIDO_BENEFICIARIO'] == ordenante['APELLIDO_ORDENANTE'] or\n",
    "                b['APELLIDO_BENEFICIARIO'] == ordenante['SEGUNDO_APELLIDO_ORDENANTE']\n",
    "            )\n",
    "        ]\n",
    "        beneficiarios_seleccionados.append(random.choice(beneficiarios_posibles) if beneficiarios_posibles else random.choice(beneficiarios))\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # 8. Construcción del DataFrame base con todas las transacciones\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    data = {\n",
    "        \"NUMERO_TRANSACCION\": [generar_numero_transaccion() for _ in range(num_transacciones)],\n",
    "        \"FECHA\": fechas_aleatorias,\n",
    "        \"HORA\": horas_aleatorias,\n",
    "        \"IMPORTE\": importes_aleatorios,\n",
    "        \"ESTADO_OPERACION\": estados_operacion,\n",
    "        \"PAIS_ORIGEN\": ['España'] * num_transacciones,\n",
    "    }\n",
    "\n",
    "    # --- Inyectamos datos de ordenantes y beneficiarios (campo a campo) ---\n",
    "    for j, ordenante in enumerate(ordenantes_seleccionados):\n",
    "        for key, value in ordenante.items():\n",
    "            data.setdefault(key, [None] * num_transacciones)\n",
    "            data[key][j] = value\n",
    "\n",
    "    for j, beneficiario in enumerate(beneficiarios_seleccionados):\n",
    "        for key, value in beneficiario.items():\n",
    "            data.setdefault(key, [None] * num_transacciones)\n",
    "            data[key][j] = value\n",
    "        # Aseguramos que el flag es_Agente existe (por si falta)\n",
    "        ordenante.setdefault(\"es_Agente\", False)\n",
    "\n",
    "    # Asignamos ciudad, sujeto y agente (las mismas para todo el fichero)\n",
    "    data['ENT_TOW_CIT_RES'] = [distribucion_localidades.loc[index_seleccionado, 'ENT_TOW_CIT_RES']] * num_transacciones\n",
    "    data['ENT_COD_PAR_ENT'] = [distribucion_localidades.loc[index_seleccionado, 'ENT_COD_PAR_ENT']] * num_transacciones\n",
    "    data['ENT_NAT_REF_COD'] = [agente_del_fichero] * num_transacciones\n",
    "\n",
    "    # Flag es_Agente: True si coincide con el agente designado\n",
    "    data[\"es_Agente\"] = [o[\"NUM_DOC_ORDENANTE\"] == doc_agente_designado for o in ordenantes_seleccionados]\n",
    "\n",
    "    # --- DataFrame inicial ---\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # 9. Inyección de patrones de riesgo (cuckoo smurfing, fraccionamiento…)\n",
    "    # -------------------------------------------------------------------\n",
    "    # \n",
    "\n",
    "    # 9.1 Tramas concentradas y distribuidas ---------------------------------------------------\n",
    "    agentes_unicos = df[\"ENT_NAT_REF_COD\"].unique().tolist()\n",
    "    num_agentes = len(agentes_unicos)\n",
    "\n",
    "    p_concentrado = 0.10            # 10 % agentes con trama concentrada\n",
    "    p_distribuido = 0.10            # otros 10 % en clústeres distribuidos\n",
    "\n",
    "    num_concentrado = max(1, int(num_agentes * p_concentrado))\n",
    "    num_distribuido_clusters = max(1, int(num_agentes * p_distribuido))\n",
    "\n",
    "    agentes_concentrado = random.sample(agentes_unicos, num_concentrado)\n",
    "    agentes_restantes = [a for a in agentes_unicos if a not in agentes_concentrado]\n",
    "    random.shuffle(agentes_restantes)\n",
    "\n",
    "    cluster_size = max(2, len(agentes_restantes) // num_distribuido_clusters)\n",
    "    clusters_distribuido = [\n",
    "        agentes_restantes[i*cluster_size:(i+1)*cluster_size]\n",
    "        for i in range(num_distribuido_clusters)\n",
    "        if agentes_restantes[i*cluster_size:(i+1)*cluster_size]\n",
    "    ]\n",
    "\n",
    "    # -- Inyección de transacciones smurfing concentradas --\n",
    "    for agente in agentes_concentrado:\n",
    "        beneficiario_central = {\n",
    "            \"NOMBRE_BENEFICIARIO\": \"Central\",\n",
    "            \"APELLIDO_BENEFICIARIO\": \"Beneficiario\",\n",
    "            \"SEGUNDO_APELLIDO_BENEFICIARIO\": \"\",\n",
    "            \"PAIS_DESTINO\": random.choice([\"España\", \"Francia\", \"Italia\"])\n",
    "        }\n",
    "        num_transacciones_conc = random.randint(2, 5)\n",
    "        ordenantes_agente = [o for o in ordenantes_seleccionados if o.get(\"ENT_NAT_REF_COD\") == agente] or ordenantes_seleccionados\n",
    "        for _ in range(num_transacciones_conc):\n",
    "            ordenante = random.choice(ordenantes_agente)\n",
    "            df = df.append({\n",
    "                \"NUMERO_TRANSACCION\": generar_numero_transaccion(),\n",
    "                \"FECHA\": random.choice(fechas_aleatorias),\n",
    "                \"HORA\": random.choice(horas_aleatorias),\n",
    "                \"IMPORTE\": random.randint(10, 200),\n",
    "                \"ESTADO_OPERACION\": \"EXITOSA\",\n",
    "                \"PAIS_ORIGEN\": \"España\",\n",
    "                \"NOMBRE_ORDENANTE\": ordenante[\"NOMBRE_ORDENANTE\"],\n",
    "                \"APELLIDO_ORDENANTE\": ordenante[\"APELLIDO_ORDENANTE\"],\n",
    "                \"SEGUNDO_APELLIDO_ORDENANTE\": ordenante.get(\"SEGUNDO_APELLIDO_ORDENANTE\", \"\"),\n",
    "                \"PAIS_DOC_ORDENANTE\": ordenante[\"PAIS_DOC_ORDENANTE\"],\n",
    "                \"NUM_DOC_ORDENANTE\": ordenante[\"NUM_DOC_ORDENANTE\"],\n",
    "                \"PAIS_NAC_ORDENANTE\": ordenante[\"PAIS_NAC_ORDENANTE\"],\n",
    "                \"FECHA_NAC_ORDENANTE\": ordenante[\"FECHA_NAC_ORDENANTE\"],\n",
    "                \"es_Agente\": False,\n",
    "                \"NOMBRE_BENEFICIARIO\": beneficiario_central[\"NOMBRE_BENEFICIARIO\"],\n",
    "                \"APELLIDO_BENEFICIARIO\": beneficiario_central[\"APELLIDO_BENEFICIARIO\"],\n",
    "                \"SEGUNDO_APELLIDO_BENEFICIARIO\": beneficiario_central[\"SEGUNDO_APELLIDO_BENEFICIARIO\"],\n",
    "                \"PAIS_DESTINO\": beneficiario_central[\"PAIS_DESTINO\"],\n",
    "                \"ENT_TOW_CIT_RES\": distribucion_localidades.loc[index_seleccionado, 'ENT_TOW_CIT_RES'],\n",
    "                \"ENT_COD_PAR_ENT\": distribucion_localidades.loc[index_seleccionado, 'ENT_COD_PAR_ENT'],\n",
    "                \"ENT_NAT_REF_COD\": agente,\n",
    "            }, ignore_index=True)\n",
    "\n",
    "    # -- Inyección de transacciones smurfing distribuidas --\n",
    "    for cluster in clusters_distribuido:\n",
    "        beneficiario_distribuido = {\n",
    "            \"NOMBRE_BENEFICIARIO\": \"Distribuido\",\n",
    "            \"APELLIDO_BENEFICIARIO\": \"Beneficiario\",\n",
    "            \"SEGUNDO_APELLIDO_BENEFICIARIO\": \"\",\n",
    "            \"PAIS_DESTINO\": random.choice([\"España\", \"Francia\", \"Italia\"])\n",
    "        }\n",
    "        num_transacciones_cluster = random.randint(1, 3)\n",
    "        for agente in cluster:\n",
    "            ordenantes_agente = [o for o in ordenantes_seleccionados if o.get(\"ENT_NAT_REF_COD\") == agente] or ordenantes_seleccionados\n",
    "            for _ in range(num_transacciones_cluster):\n",
    "                ordenante = random.choice(ordenantes_agente)\n",
    "                df = df.append({\n",
    "                    \"NUMERO_TRANSACCION\": generar_numero_transaccion(),\n",
    "                    \"FECHA\": random.choice(fechas_aleatorias),\n",
    "                    \"HORA\": random.choice(horas_aleatorias),\n",
    "                    \"IMPORTE\": random.randint(10, 200),\n",
    "                    \"ESTADO_OPERACION\": \"EXITOSA\",\n",
    "                    \"PAIS_ORIGEN\": \"España\",\n",
    "                    \"NOMBRE_ORDENANTE\": ordenante[\"NOMBRE_ORDENANTE\"],\n",
    "                    \"APELLIDO_ORDENANTE\": ordenante[\"APELLIDO_ORDENANTE\"],\n",
    "                    \"SEGUNDO_APELLIDO_ORDENANTE\": ordenante.get(\"SEGUNDO_APELLIDO_ORDENANTE\", \"\"),\n",
    "                    \"PAIS_DOC_ORDENANTE\": ordenante[\"PAIS_DOC_ORDENANTE\"],\n",
    "                    \"NUM_DOC_ORDENANTE\": ordenante[\"NUM_DOC_ORDENANTE\"],\n",
    "                    \"PAIS_NAC_ORDENANTE\": ordenante[\"PAIS_NAC_ORDENANTE\"],\n",
    "                    \"FECHA_NAC_ORDENANTE\": ordenante[\"FECHA_NAC_ORDENANTE\"],\n",
    "                    \"es_Agente\": False,\n",
    "                    \"NOMBRE_BENEFICIARIO\": beneficiario_distribuido[\"NOMBRE_BENEFICIARIO\"],\n",
    "                    \"APELLIDO_BENEFICIARIO\": beneficiario_distribuido[\"APELLIDO_BENEFICIARIO\"],\n",
    "                    \"SEGUNDO_APELLIDO_BENEFICIARIO\": beneficiario_distribuido[\"SEGUNDO_APELLIDO_BENEFICIARIO\"],\n",
    "                    \"PAIS_DESTINO\": beneficiario_distribuido[\"PAIS_DESTINO\"],\n",
    "                    \"ENT_TOW_CIT_RES\": distribucion_localidades.loc[index_seleccionado, 'ENT_TOW_CIT_RES'],\n",
    "                    \"ENT_COD_PAR_ENT\": distribucion_localidades.loc[index_seleccionado, 'ENT_COD_PAR_ENT'],\n",
    "                    \"ENT_NAT_REF_COD\": agente,\n",
    "                }, ignore_index=True)\n",
    "\n",
    "    # 9.2 Otros indicadores de riesgo ----------------------------------------------------------\n",
    "    # (A) Concentra 70 % de transacciones de riesgo en el 20 % de agentes\n",
    "    total_trans = len(df)\n",
    "    num_riesgo = max(1, int(total_trans * random.uniform(0.05, 0.10)))\n",
    "    agentes_unicos = df[\"ENT_NAT_REF_COD\"].unique().tolist()\n",
    "    random.shuffle(agentes_unicos)\n",
    "    top_count = max(1, int(len(agentes_unicos) * 0.2))\n",
    "    top_agentes, otros_agentes = agentes_unicos[:top_count], agentes_unicos[top_count:]\n",
    "    indices_top = df.index[df[\"ENT_NAT_REF_COD\"].isin(top_agentes)].tolist()\n",
    "    indices_otros = df.index[df[\"ENT_NAT_REF_COD\"].isin(otros_agentes)].tolist()\n",
    "    num_riesgo_top = min(len(indices_top), int(num_riesgo * 0.7))\n",
    "    num_riesgo_otros = min(len(indices_otros), num_riesgo - num_riesgo_top)\n",
    "    indices_riesgo = random.sample(indices_top, num_riesgo_top) + random.sample(indices_otros, num_riesgo_otros)\n",
    "\n",
    "    # (B) Documentos repetidos con nombre distinto ---------------------------------------------\n",
    "    for idx in indices_riesgo:\n",
    "        df.loc[idx, [\"NOMBRE_ORDENANTE\", \"APELLIDO_ORDENANTE\"]] = [faker.first_name(), faker.last_name()]\n",
    "        df.loc[idx, \"SEGUNDO_APELLIDO_ORDENANTE\"] = faker.last_name() if random.random() > 0.2 else ''\n",
    "\n",
    "    # (C) Documentos erróneos ------------------------------------------------------------------\n",
    "    def validoDNI(dni: str) -> bool:\n",
    "        tabla = \"TRWAGMYFPDXBNJZSQVHLCKE\"; dig_ext = \"XYZ\"; reemp = {'X': '0', 'Y': '1', 'Z': '2'}\n",
    "        dni = dni.upper()\n",
    "        if len(dni) == 9:\n",
    "            num, dig_control = dni[:8], dni[8]\n",
    "            num = num.replace(num[0], reemp.get(num[0], num[0])) if num[0] in dig_ext else num\n",
    "            return num.isdigit() and tabla[int(num) % 23] == dig_control\n",
    "        return False\n",
    "\n",
    "    num_riesgo_doc_err = max(0, int(total_trans * random.uniform(0.01, 0.02)))\n",
    "    indices_riesgo_doc_err = random.sample(list(df.index), num_riesgo_doc_err)\n",
    "    for idx in indices_riesgo_doc_err:\n",
    "        df.loc[idx, \"NUM_DOC_ORDENANTE\"] = \"ZZZ\" + ''.join(random.choices(\"0123456789ABCDEF\", k=5))\n",
    "\n",
    "    # (D) Fraccionamiento (> 3 000 €) ---------------------------------------------------------\n",
    "    num_riesgo_fracc = max(0, int(total_trans * 0.01))\n",
    "    indices_fracc = random.sample(list(df.index), num_riesgo_fracc)\n",
    "    for idx in indices_fracc:\n",
    "        base_imp = df.loc[idx, \"IMPORTE\"]\n",
    "        if base_imp < 3000:\n",
    "            nuevos_importes = [random.randint(800, 1500) for _ in range(3)]\n",
    "            if sum(nuevos_importes) < 3001:\n",
    "                nuevos_importes[0] += 3001 - sum(nuevos_importes)\n",
    "            for imp in nuevos_importes:\n",
    "                nueva_fila = df.loc[idx].copy()\n",
    "                nueva_fila[\"IMPORTE\"] = imp\n",
    "                nueva_fila[\"NUMERO_TRANSACCION\"] = \"TXN-FRAC-\" + ''.join(random.choices('ABC123', k=5))\n",
    "                df = df.append(nueva_fila, ignore_index=True)\n",
    "            df.drop(idx, inplace=True)\n",
    "\n",
    "    # (E) Envíos repetidos a un mismo beneficiario (> 10 000 € / mes) -------------------------\n",
    "    num_riesgo_benef = max(0, int(total_trans * 0.012))\n",
    "    indices_riesgo_benef = random.sample(list(df.index), num_riesgo_benef)\n",
    "    for idx in indices_riesgo_benef:\n",
    "        random_month, random_day = random.randint(1, 12), random.randint(1, 28)\n",
    "        fecha_fija = f\"{random_day:02d}/{random_month:02d}/2023\"\n",
    "        suma, transacciones_extra = 0, []\n",
    "        while suma < 10001:\n",
    "            imp = random.randint(2000, 3000)\n",
    "            suma += imp\n",
    "            nueva_fila = df.loc[idx].copy()\n",
    "            nueva_fila.update({\n",
    "                \"IMPORTE\": imp,\n",
    "                \"NUMERO_TRANSACCION\": \"TXN-HIGH-\" + ''.join(random.choices('XYZ987', k=5)),\n",
    "                \"FECHA\": fecha_fija,\n",
    "            })\n",
    "            transacciones_extra.append(nueva_fila)\n",
    "        df = pd.concat([df.drop(idx), pd.DataFrame(transacciones_extra)], ignore_index=True)\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # 10. Etiquetas PEP (personas políticamente expuestas)\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    df['es_PEP'] = False\n",
    "    pep_idx = np.random.choice(df.index, size=max(1, int(len(df) * 0.005)), replace=False)\n",
    "    df.loc[pep_idx, 'es_PEP'] = True\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # 11. Aseguramos que el agente designado aparezca marcado como tal\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    codigo_agente = df[\"ENT_NAT_REF_COD\"].iloc[0]\n",
    "    agente_designado = designated_agents[codigo_agente]\n",
    "    if not any(o[\"NUM_DOC_ORDENANTE\"] == agente_designado[\"NUM_DOC_ORDENANTE\"] for o in ordenantes_seleccionados):\n",
    "        ordenantes_seleccionados[0] = agente_designado\n",
    "        for key, value in agente_designado.items():\n",
    "            df.at[0, key] = value\n",
    "    df.loc[df['NUM_DOC_ORDENANTE'] == agente_designado[\"NUM_DOC_ORDENANTE\"], \"es_Agente\"] = True\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # 12. Serialización a CSV\n",
    "    # -------------------------------------------------------------------\n",
    "    sujeto_obligado_nombre = df['ENT_COD_PAR_ENT'].iloc[0].replace(\" \", \"_\") if 'ENT_COD_PAR_ENT' in df.columns else \"Desconocido\"\n",
    "    agente_nombre = df['ENT_NAT_REF_COD'].iloc[0].replace(\" \", \"_\") if 'ENT_NAT_REF_COD' in df.columns else \"Desconocido\"\n",
    "    nombre_fichero = f\"{sujeto_obligado_nombre}__{agente_nombre}.csv\"\n",
    "    df.to_csv(nombre_fichero, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Fichero {nombre_fichero} generado con {num_transacciones} transacciones.\")\n",
    "\n",
    "print(\"Todos los ficheros CSV han sido generados.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
